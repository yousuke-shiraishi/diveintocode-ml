{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAKxMFRMtWj2"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_Vs5bGS_ti8P",
    "outputId": "7d0f49ac-eb76-41b2-8221-36c7554e4812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sBGV7WgtklD"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYTjoTm2ts12"
   },
   "outputs": [],
   "source": [
    "# !mkdir /root/.kaggle\n",
    "# !mv kaggle.json /root/.kaggle/kaggle.json\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "# !kaggle competitions download -c tgs-salt-identification-challenge\n",
    "!unzip train.zip -d train　> /dev/null 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "07kGsOXatzY0",
    "outputId": "7e115202-a9cc-49a7-b064-711b564aa1ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6kXW2tJt3gN"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/Colab Notebooks/DIC/sprint21/unet-master/tgs-salt-identification-challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AwRaSZq6Udwd",
    "outputId": "17a48f2e-2a44-4494-f179-6d5f9129ae2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/DIC/sprint21/unet-master/tgs-salt-identification-challenge'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7ytgEeDxnjY"
   },
   "source": [
    "###【問題1】コードレビュー\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "視点例\n",
    "\n",
    "Sprint20で使用した実装とはどのように違うのか\n",
    "転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQWDx9ncx7y1"
   },
   "source": [
    "カスタム・メトリックと損失関数を定義する\n",
    "損失とメトリック関数の定義は Keras では単純である。与えられたサンプルに対する True ラベルと同じ与えられたサンプルに対する予測ラベルを取る関数を単純に定義する。\n",
    "\n",
    "Dice 損失は overlap を計測するメトリックです。Dice 係数 (dice 損失) のための最適化についてのより多くの情報はこの [論文](http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf)で見つかる。\n",
    "\n",
    "ここでは dice 損失を使用する、何故ならば設計上それはクラス不均衡な問題でより良い遂行をするからである。そして、dice 係数と IoU メトリックの最大化はセグメンテーション・タスクの実際の目的と目標である。交差エントロピーの使用はより代理的ですが、最大化するのはより簡単である。代わりに、目的を直接的に最大化する。\n",
    "詳しいコードは[https://github.com/shibuiwilliam/Keras_Autoencoder/blob/master/Cifar_Conv_AutoEncoder_UNET.ipynb](https://github.com/shibuiwilliam/Keras_Autoencoder/blob/master/Cifar_Conv_AutoEncoder_UNET.ipynb)に記載されている。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FYigw1U9Ut6"
   },
   "source": [
    "Kerasで使える誤差関数\n",
    "Kerasでは，学習において最小化したい関数をloss function，学習とは無関係にモデルの性能評価のために用意する関数をmetricと呼び，日本語マニュアルでは前者を誤差関数，後者を評価関数と訳している。[利用可能な損失関数](https://keras.io/ja/losses/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPhSiYqCA7Vx"
   },
   "source": [
    "VGG16やRESNETにget_layerでレイヤーを追加してmodelのレイヤーを作っている。\n",
    "VGGの場合はKerasではVGG16モデルがkeras.applications.vgg16モジュールに実装されているため簡単に使える。http://aidiary.hatenablog.com/entry/20170104/1483535144\n",
    "\n",
    "従来のモデルでは各層（Deep path）を通して勾配の計算を行っているが，ResNetは新たに別の経路（Shortcut Connection）を設けることで，勾配消失を起こしにくくしたモデルです．その結果，ResNetは精度を上げつつ深い階層のネットワークを実現している。[ResNetをFine Tuningして自分が用意した画像を学習させる](https://pchun.work/resnet%E3%82%92fine-tuning%E3%81%97%E3%81%A6%E8%87%AA%E5%88%86%E3%81%8C%E7%94%A8%E6%84%8F%E3%81%97%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%95%E3%81%9B%E3%82%8B/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6_IAIU-Mk91"
   },
   "source": [
    "###転移学習をどのように行っているか\n",
    "weights='imagenet'を設定しているのでここから重みを引っ張ってくる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8w1WTHjofjh"
   },
   "source": [
    "# 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X-RSmawqtWj3",
    "outputId": "c2499e87-bee3-4b3d-be14-d26a0b92a9ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16 #追加２０１９・６・１８\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqKRCFzvtWj9"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3apY2EyttWkA"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hV6_fxU9tWkC"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bi05MeFcJv4t",
    "outputId": "e3cbab03-c09a-4374-8bc4-1c389799658c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/DIC/sprint21/unet-master/tgs-salt-identification-challenge\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "zy3WYNk_5x7q",
    "outputId": "f75711dd-4be8-4a56-8587-a63caa848115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-models_pretrained_and_more.ipynb\ttest\n",
      "03-models_pretrained_and_morevgg.ipynb\ttest.zip\n",
      "clean-workflow-in-keras.ipynb\t\ttrain\n",
      "depths.csv\t\t\t\ttrain.csv\n",
      "input\t\t\t\t\ttrain.zip\n",
      "sample_submission.csv\t\t\tunet_resnet.h5\n",
      "sprint21_segmentation2.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "1O1y2X6-tWkD",
    "outputId": "288bbb14-d502-434f-e340-02194d8cd4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train_vgg.csv')\n",
    "test = pd.read_csv('./input/sample_submission_vgg.csv')\n",
    "depth = pd.read_csv('./input/depths_vgg.csv')\n",
    "\n",
    "train_src = './train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR0M72xltWkG"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zboe61NrtWkH",
    "outputId": "0a8e2ec8-4f27-421c-94f7-06343c13db87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(\n",
    "    [cv2.imread('./train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.array(\n",
    "    [cv2.imread('./train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o51Ztwthgfct"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "lCzm5i99tWkJ",
    "outputId": "ed08be25-ddfa-4740-db2a-f581d0c4e2ed",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f31b9f126d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qloUmbM1tWkN"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9bdPGr3GmMa"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9OW8ASTtWkO"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YF76qOHTtWkQ"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NuBv-QuytWkR",
    "outputId": "9cfc5675-4ade-4c87-c1d2-5e4af8ec00b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wQgAIvpxHc1U",
    "outputId": "60a13d4b-eeb3-4015-f17a-ecb268006d83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 06:55:12.322496 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0719 06:55:12.361370 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 06:55:12.371383 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0719 06:55:12.422449 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0719 06:55:13.008768 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0719 06:55:13.010285 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=(224, 224, 3)))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9LPtRNqtWkV"
   },
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbKdIvvJtWkV"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "igm9zWAotWka"
   },
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgBK4OyCtWkb"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSJG0TyetWkc"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F98z6AIUtWkf"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5LsPfyvtWkj"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEtB5b3jxnI6"
   },
   "source": [
    "VGG16で学習モデルを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBqp05uTSQvO"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_VGG16(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nd5y2YtKZcrs",
    "outputId": "61e9fbab-cb43-450e-a29e-f98cb390c286"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 06:57:04.040741 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0719 06:57:04.148506 139853084845952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0719 06:57:04.940013 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0719 06:57:06.736363 139853084845952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0719 06:57:06.771626 139853084845952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0719 06:57:06.810397 139853084845952 deprecation.py:323] From <ipython-input-19-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,677,489\n",
      "Trainable params: 28,672,209\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/10\n",
      "3196/3196 [==============================] - 237s 74ms/step - loss: 0.8431 - my_iou_metric: 0.1681 - val_loss: 2.1365 - val_my_iou_metric: 0.1815\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.18147, saving model to unet_VGG16.h5\n",
      "Epoch 2/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.6678 - my_iou_metric: 0.2498 - val_loss: 1.4859 - val_my_iou_metric: 0.3072\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.18147 to 0.30721, saving model to unet_VGG16.h5\n",
      "Epoch 3/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.6300 - my_iou_metric: 0.3326 - val_loss: 1.5988 - val_my_iou_metric: 0.2356\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.30721\n",
      "Epoch 4/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.5847 - my_iou_metric: 0.3940 - val_loss: 0.5766 - val_my_iou_metric: 0.4748\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.30721 to 0.47475, saving model to unet_VGG16.h5\n",
      "Epoch 5/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.5666 - my_iou_metric: 0.4135 - val_loss: 0.7402 - val_my_iou_metric: 0.3641\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.47475\n",
      "Epoch 6/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.5268 - my_iou_metric: 0.4344 - val_loss: 0.6060 - val_my_iou_metric: 0.4189\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.47475\n",
      "Epoch 7/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.5137 - my_iou_metric: 0.4528 - val_loss: 0.6180 - val_my_iou_metric: 0.3842\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.47475\n",
      "Epoch 8/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.4932 - my_iou_metric: 0.4660 - val_loss: 0.7384 - val_my_iou_metric: 0.4529\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.47475\n",
      "Epoch 9/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.4775 - my_iou_metric: 0.4819 - val_loss: 0.4526 - val_my_iou_metric: 0.5915\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.47475 to 0.59154, saving model to unet_VGG16.h5\n",
      "Epoch 10/10\n",
      "3196/3196 [==============================] - 213s 67ms/step - loss: 0.4713 - my_iou_metric: 0.4944 - val_loss: 1.2575 - val_my_iou_metric: 0.4228\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.59154\n"
     ]
    }
   ],
   "source": [
    "#K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "model_depth = unet_VGG16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_VGG16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 10  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0mtLnnAtWko"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovaAjHYltWkt"
   },
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZNQjrSCtWku"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uho-2vUltWkx"
   },
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1iy96-AtWkx"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-t86aqv7tWkz",
    "outputId": "338bea30-d696-4560-85cd-d838910c3246"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:46<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "6UEYSeqntWk3",
    "outputId": "bf2adeb0-1a31-477f-f542-41845a5e23fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4792 at threshold: 0.260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.464460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.005921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.457587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.459391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.463433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.467475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.479229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.464460\n",
       "std     0.204939   0.005921\n",
       "min     0.200000   0.457587\n",
       "25%     0.370000   0.459391\n",
       "50%     0.540000   0.463433\n",
       "75%     0.710000   0.467475\n",
       "max     0.880000   0.479229"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 閾値を超えたIoU値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "id": "K_cWaRujtWk6",
    "outputId": "230675f8-bd76-4252-e9f6-cfde0836e696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3167a02da0>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAIaCAYAAADiE8FNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4iIiIh46f8B3OIAq3ZSnIYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pai9kvE-tWk8"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpMR3RiFtWk8"
   },
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03-models_pretrained_and_morevgg.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
