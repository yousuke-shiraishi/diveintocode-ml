{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAKxMFRMtWj2"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1560913543265,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "_Vs5bGS_ti8P",
    "outputId": "4e375d0f-827d-418e-b915-85fc17a1dd51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sBGV7WgtklD"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYTjoTm2ts12"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1560913554236,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "07kGsOXatzY0",
    "outputId": "7396ca5a-94fd-4f64-b623-920bc59f7536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/DIC/sprint21/unet-master/tgs-salt-identification-challenge'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6kXW2tJt3gN"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/Colab Notebooks/DIC/sprint21/unet-master/tgs-salt-identification-challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1560907810998,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "AwRaSZq6Udwd",
    "outputId": "b211f81e-e426-4bf1-db1d-065173c3fd54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/DIC/sprint21/unet-master/tgs-salt-identification-challenge'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7ytgEeDxnjY"
   },
   "source": [
    "###【問題1】コードレビュー\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "視点例\n",
    "\n",
    "Sprint20で使用した実装とはどのように違うのか\n",
    "転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQWDx9ncx7y1"
   },
   "source": [
    "カスタム・メトリックと損失関数を定義する\n",
    "損失とメトリック関数の定義は Keras では単純である。与えられたサンプルに対する True ラベルと同じ与えられたサンプルに対する予測ラベルを取る関数を単純に定義する。\n",
    "\n",
    "Dice 損失は overlap を計測するメトリックです。Dice 係数 (dice 損失) のための最適化についてのより多くの情報はこの [論文](http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf)で見つかる。\n",
    "\n",
    "ここでは dice 損失を使用する、何故ならば設計上それはクラス不均衡な問題でより良い遂行をするからである。そして、dice 係数と IoU メトリックの最大化はセグメンテーション・タスクの実際の目的と目標である。交差エントロピーの使用はより代理的ですが、最大化するのはより簡単である。代わりに、目的を直接的に最大化する。\n",
    "詳しいコードは[https://github.com/shibuiwilliam/Keras_Autoencoder/blob/master/Cifar_Conv_AutoEncoder_UNET.ipynb](https://github.com/shibuiwilliam/Keras_Autoencoder/blob/master/Cifar_Conv_AutoEncoder_UNET.ipynb)に記載されている。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FYigw1U9Ut6"
   },
   "source": [
    "Kerasで使える誤差関数\n",
    "Kerasでは，学習において最小化したい関数をloss function，学習とは無関係にモデルの性能評価のために用意する関数をmetricと呼び，日本語マニュアルでは前者を誤差関数，後者を評価関数と訳している。[利用可能な損失関数](https://keras.io/ja/losses/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPhSiYqCA7Vx"
   },
   "source": [
    "VGG16やRESNETにget_layerでレイヤーを追加してmodelのレイヤーを作っている。\n",
    "VGGの場合はKerasではVGG16モデルがkeras.applications.vgg16モジュールに実装されているため簡単に使える。http://aidiary.hatenablog.com/entry/20170104/1483535144\n",
    "\n",
    "従来のモデルでは各層（Deep path）を通して勾配の計算を行っているが，ResNetは新たに別の経路（Shortcut Connection）を設けることで，勾配消失を起こしにくくしたモデルです．その結果，ResNetは精度を上げつつ深い階層のネットワークを実現している。[ResNetをFine Tuningして自分が用意した画像を学習させる](https://pchun.work/resnet%E3%82%92fine-tuning%E3%81%97%E3%81%A6%E8%87%AA%E5%88%86%E3%81%8C%E7%94%A8%E6%84%8F%E3%81%97%E3%81%9F%E7%94%BB%E5%83%8F%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%95%E3%81%9B%E3%82%8B/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6_IAIU-Mk91"
   },
   "source": [
    "###転移学習をどのように行っているか\n",
    "weights='imagenet'を設定しているのでここから重みを引っ張ってくる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8w1WTHjofjh"
   },
   "source": [
    "# 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-RSmawqtWj3"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16 #追加２０１９・６・１８\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqKRCFzvtWj9"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3apY2EyttWkA"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hV6_fxU9tWkC"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1560913575356,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "1O1y2X6-tWkD",
    "outputId": "c5e88154-cf97-4733-e49e-d19bf3c00710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/sample_submission.csv')\n",
    "depth = pd.read_csv('./input/depths.csv')\n",
    "\n",
    "train_src = './train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR0M72xltWkG"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27278,
     "status": "ok",
     "timestamp": 1560913607784,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "zboe61NrtWkH",
    "outputId": "667824db-3c5a-42c7-b04c-33b5a7f052fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1560914265050,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "lCzm5i99tWkJ",
    "outputId": "036f984c-59ab-4fee-8cf8-0e0d44dd7de6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3bf40838d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qloUmbM1tWkN"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9OW8ASTtWkO"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YF76qOHTtWkQ"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16618,
     "status": "ok",
     "timestamp": 1560914294551,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "NuBv-QuytWkR",
    "outputId": "1afba1c3-3064-4510-aa1e-12bfd34bb446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9LPtRNqtWkV"
   },
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbKdIvvJtWkV"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtI0F2ootWkZ"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "igm9zWAotWka"
   },
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgBK4OyCtWkb"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSJG0TyetWkc"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F98z6AIUtWkf"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myrL3bpatWkg"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False,use_res_net=True):\n",
    "    if use_res_net == True:\n",
    "        # Base model - encoder\n",
    "        base_model = ResNet50(input_shape=input_size, include_top=False,weights=weights)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5LsPfyvtWkj"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEtB5b3jxnI6"
   },
   "source": [
    "RESNETで学習モデルを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24948,
     "status": "ok",
     "timestamp": 1560914546455,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "ombWzEZUtWkj",
    "outputId": "7e54176b-f81f-4e6d-d091-f17b7849f9ba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0619 03:22:01.856750 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0619 03:22:01.858610 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0619 03:22:01.906526 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0619 03:22:01.907930 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0619 03:22:01.914445 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0619 03:22:05.122550 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0619 03:22:05.201947 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 03:22:25.551623 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0619 03:22:25.938554 139896985175936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0619 03:22:25.962341 139896985175936 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0619 03:22:25.979466 139896985175936 deprecation.py:323] From <ipython-input-25-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "use_net_flag = True\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet',use_res_net=use_net_flag)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0mtLnnAtWko"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9880
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 338727,
     "status": "ok",
     "timestamp": 1560914942117,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "g2FnU6LatWkq",
    "outputId": "fe2720be-47c9-4f30-9a7f-729066d14134",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W0619 03:23:31.763471 139896985175936 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n",
      "3196/3196 [==============================] - 158s 49ms/step - loss: 0.7377 - my_iou_metric: 0.3102 - val_loss: 1.0932 - val_my_iou_metric: 0.4792\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.47923, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3196/3196 [==============================] - 113s 35ms/step - loss: 0.5626 - my_iou_metric: 0.4874 - val_loss: 0.7633 - val_my_iou_metric: 0.5484\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.47923 to 0.54838, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False,use_res_net=use_net_flag)\n",
    "print(model_depth.summary())\n",
    "\n",
    "if use_net_flag == True:\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "        save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_my_iou_metric',\n",
    "        mode='max',\n",
    "        factor=0.5, \n",
    "        patience=5, \n",
    "        min_lr=0.0001, \n",
    "        verbose=1)\n",
    "else:\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "        save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_my_iou_metric',\n",
    "        mode='max',\n",
    "        factor=0.5, \n",
    "        patience=5, \n",
    "        min_lr=0.0001, \n",
    "        verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovaAjHYltWkt"
   },
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZNQjrSCtWku"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uho-2vUltWkx"
   },
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1iy96-AtWkx"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36549,
     "status": "ok",
     "timestamp": 1560915013283,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "-t86aqv7tWkz",
    "outputId": "67347634-a97f-48d4-cdb4-30e982265aea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:35<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1560915021887,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "6UEYSeqntWk3",
    "outputId": "97a7e419-cbf3-4295-9ba7-eeab98404187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5734 at threshold: 0.580\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.562886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.009098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.541294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.565547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.573383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.562886\n",
       "std     0.204939   0.009098\n",
       "min     0.200000   0.541294\n",
       "25%     0.370000   0.558333\n",
       "50%     0.540000   0.565547\n",
       "75%     0.710000   0.569900\n",
       "max     0.880000   0.573383"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1511,
     "status": "ok",
     "timestamp": 1560915041150,
     "user": {
      "displayName": "Yousuke Shiraishi",
      "photoUrl": "",
      "userId": "10274436893917421768"
     },
     "user_tz": -540
    },
    "id": "K_cWaRujtWk6",
    "outputId": "289836de-22f6-4bcc-e3f8-b0f202603914"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b8c484550>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAIaCAYAAADiE8FNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/+dAY4oz9o0ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pai9kvE-tWk8"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpMR3RiFtWk8"
   },
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03-models_pretrained_and_more.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
